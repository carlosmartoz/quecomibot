// Environment variables
require("dotenv").config();

// Required dependencies
const TelegramBot = require("node-telegram-bot-api");
const OpenAI = require("openai");
const fs = require("fs");
const https = require("https");

// Get environment variables
const TELEGRAM_TOKEN = process.env.TELEGRAM_TOKEN;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const ASSISTANT_ID = process.env.ASSISTANT_ID;

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
});

// Create a fake server to keep Render from complaining
const PORT = 3000;

// Create a fake server to keep Render from complaining
https
  .createServer((req, res) => {
    res.write("QueComÃ­ is running...");

    res.end();
  })
  .listen(PORT, () => {
    console.log(`âœ… QueComÃ­ is running on port ${PORT}`);
  });

let bot;

// Check if there is a previous instance running
if (bot) {
  console.log("ğŸ›‘ Stopping previous instance...");

  bot.stopPolling();
}

// Initialize Telegram bot with polling
bot = new TelegramBot(TELEGRAM_TOKEN, { polling: true });

// Store user conversations and meals
const userThreads = new Map();
const userMeals = new Map();

// Get existing thread for user or create new one
async function getOrCreateThread(userId) {
  if (!userThreads.has(userId)) {
    const thread = await openai.beta.threads.create();

    userThreads.set(userId, thread.id);

    userMeals.set(userId, []);
  }

  return userThreads.get(userId);
}

// Download file from Telegram and return as buffer
async function downloadFile(fileLink) {
  return new Promise((resolve, reject) => {
    https.get(fileLink, (response) => {
      const chunks = [];

      response.on("data", (chunk) => chunks.push(chunk));

      response.on("end", () => resolve(Buffer.concat(chunks)));

      response.on("error", reject);
    });
  });
}

// Transcribe audio file using OpenAI Whisper API
async function transcribeAudio(audioBuffer) {
  try {
    const tempFilePath = `temp_${Date.now()}.ogg`;
    fs.writeFileSync(tempFilePath, audioBuffer);

    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempFilePath),
      model: "whisper-1",
    });

    fs.unlinkSync(tempFilePath);

    return transcription.text;
  } catch (error) {
    console.error("Error transcribing audio:", error);

    throw error;
  }
}

// Process message with OpenAI Assistant
async function processMessageWithAI(threadId, content, isImage = false) {
  try {
    if (isImage) {
      await openai.beta.threads.messages.create(threadId, {
        role: "user",
        content: [
          {
            type: "text",
            text: "Analiza esta imagen de comida y proporciona las calorÃ­as aproximadas y macronutrientes. Si ves varios alimentos, lista cada uno por separado.",
          },
          {
            type: "image_url",
            image_url: {
              url: content,
            },
          },
        ],
      });
    } else {
      await openai.beta.threads.messages.create(threadId, {
        role: "user",
        content: `Analiza el siguiente mensaje y extrae los alimentos mencionados, ignorando verbos como "desayunÃ©", "almorcÃ©", "comÃ­", "cenÃ©", etc. Proporciona las calorÃ­as aproximadas y macronutrientes para: ${content}`,
      });
    }

    const run = await openai.beta.threads.runs.create(threadId, {
      assistant_id: ASSISTANT_ID,
    });

    let runStatus;

    do {
      const runStatusResponse = await openai.beta.threads.runs.retrieve(
        threadId,
        run.id
      );

      runStatus = runStatusResponse.status;

      if (runStatus === "failed" || runStatus === "expired") {
        throw new Error(`Run ended with status: ${runStatus}`);
      }

      if (runStatus !== "completed") {
        await new Promise((resolve) => setTimeout(resolve, 1000));
      }
    } while (runStatus !== "completed");

    const messages = await openai.beta.threads.messages.list(threadId);

    const lastMessage = messages.data[0];

    return lastMessage.content[0].text.value;
  } catch (error) {
    console.error("Error processing message with AI:", error);

    return "Â¡Ups! ğŸ™ˆ Parece que mi cerebro nutricional estÃ¡ haciendo una pequeÃ±a siesta digestiva ğŸ˜´. \n\n Â¿PodrÃ­as intentarlo de nuevo en un momento? Â¡Prometo estar mÃ¡s despierto! ğŸŒŸ";
  }
}

// Save meal information for a user
function saveMealForUser(userId, mealInfo) {
  if (!userMeals.has(userId)) {
    userMeals.set(userId, []);
  }

  const meals = userMeals.get(userId);

  meals.push({
    timestamp: new Date(),
    info: mealInfo,
  });
}

// Get daily summary of meals for a user
function getDailySummary(userId) {
  if (!userMeals.has(userId) || userMeals.get(userId).length === 0) {
    return "No has registrado comidas hoy.";
  }

  const meals = userMeals.get(userId);

  let summary = "ğŸ“‹ Resumen del dÃ­a:\n\n";

  meals.forEach((meal, index) => {
    summary += `ğŸ• Comida ${
      index + 1
    } (${meal.timestamp.toLocaleTimeString()}):\n${meal.info}\n\n`;
  });

  userMeals.set(userId, []);

  return summary;
}

// Handle incoming messages
bot.on("message", async (msg) => {
  const chatId = msg.chat.id;

  const userId = msg.from.id;

  const threadId = await getOrCreateThread(userId);

  try {
    if (msg.text === "/start") {
      bot.sendMessage(
        chatId,
        "Â¡Hola! ğŸ‘‹ Soy tu asistente para llevar un registro de tus comidas ğŸ½ï¸ \n\n" +
          "PodÃ©s enviarme:\n" +
          "- Fotos de comidas ğŸ“¸\n" +
          "- Descripciones de lo que has comido âœï¸\n" +
          "- Mensajes de voz describiendo tus comidas ğŸ¤\n" +
          "- 'Terminar el dÃ­a' para ver tu resumen diario ğŸ“‹\n\n" +
          "Â¡Empecemos! Â¿QuÃ© has comido hoy?"
      );
      return;
    }

    if (msg.text === "Terminar el dÃ­a") {
      const summary = getDailySummary(userId);
      bot.sendMessage(chatId, summary);
      return;
    }

    let response;

    let shouldAnalyze = false;

    if (msg.photo) {
      shouldAnalyze = true;

      bot.sendMessage(
        chatId,
        "ğŸ” Â¡Detective gastronÃ³mico en acciÃ³n! Analizando tu deliciosa comida... ğŸ§âœ¨"
      );

      const photo = msg.photo[msg.photo.length - 1];

      const fileLink = await bot.getFileLink(photo.file_id);

      response = await processMessageWithAI(threadId, fileLink, true);
    } else if (msg.voice) {
      shouldAnalyze = true;

      bot.sendMessage(
        chatId,
        "ğŸ™ï¸ Â¡Escuchando atentamente tus palabras! Transformando tu audio en texto... âœ¨"
      );

      const fileLink = await bot.getFileLink(msg.voice.file_id);

      const audioBuffer = await downloadFile(fileLink);

      const transcription = await transcribeAudio(audioBuffer);

      bot.sendMessage(
        chatId,
        "ğŸ” Â¡Detective gastronÃ³mico en acciÃ³n! Analizando tu deliciosa comida... ğŸ§âœ¨"
      );

      response = await processMessageWithAI(threadId, transcription);
    } else if (msg.text) {
      shouldAnalyze = true;

      bot.sendMessage(
        chatId,
        "ğŸ” Â¡Detective gastronÃ³mico en acciÃ³n! Analizando tu deliciosa comida... ğŸ§âœ¨"
      );

      response = await processMessageWithAI(threadId, msg.text);
    }

    if (response && shouldAnalyze) {
      saveMealForUser(userId, response);

      bot.sendMessage(chatId, response);
    }
  } catch (error) {
    console.error("Error:", error);

    bot.sendMessage(
      chatId,
      "Â¡Ups! ğŸ™ˆ Parece que mi cerebro nutricional estÃ¡ haciendo una pequeÃ±a siesta digestiva ğŸ˜´. \n\n Â¿PodrÃ­as intentarlo de nuevo en un momento? Â¡Prometo estar mÃ¡s despierto! ğŸŒŸ"
    );
  }
});

// Log bot startup
console.log("ğŸ¤– QueComÃ­ Started...");
